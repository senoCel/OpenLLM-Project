# OpenLLM-Project
Erstellt mit Python 3.14

## Beschreibung
Repository für ein OpenLLM Projekt, welches sich mit der Generierung von Tipps zu verschiedenen Videospielen beschäftigt.

Arbeitsschritte: 
- Prompts ausdenken/aussuchen und optimieren (Beide)
- Persönlicher Goldstandard (Senem) 
- System laufen lassen (Niklas)
- Ergebnisse evaluieren (Beide)

## Modelle
- [mistral:7b](https://ollama.com/library/mistral:7b) 
- [falcon3:7b](https://ollama.com/library/falcon3) -> Stand 28.11 1. im Open LLM Leaderboard bei Modellen bis zu 7 Milliarden Parametern 
- [llama3.1:8b](https://ollama.com/library/llama3.1:8b)
- [qwen2.5:7b](https://ollama.com/library/qwen2.5:7b)
- [deepseek-r1:8b](https://ollama.com/library/deepseek-r1:8b)

## Games
- Assassins Creed Shadows
- Assassins Creed Origins
- Minecraft
- EA Sports FC / Fifa
- Need for Speed
- GTA V
- Mario Bros
- Rocket League
- CSGO
- Die Sims

## Erwartungen
- passender Output relativ zum Spiel -> sinnvoll
- unterschiedlicher aber hilfreicher Output -> unterschiedliche Schwerpunkte
- LLM passt sich an Spielsituationen an -> unterschiedlicher Spielerfortschritt
- LLM erkennt Erfahrungsgrad

## Prompts

### Situationen
- von Spiel abhängig
- brenzlige Situationen -> unbedingte Hilfe nötig

### Zielgruppen
- Anfänger
- Erfahrener Spieler
- verschiedene Konsolen
- Altersgruppen
  -> zB. Test, ob Kleinkind Tipps für GTA bekommt -> FSK unterschreitet

## Chats

## Ergebnisse

### Bewertungskriterien
- 
